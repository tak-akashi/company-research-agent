# プロダクト要求定義書 (Product Requirements Document)

## プロダクト概要

### 名称
**Company Research Agent** - AI-powered Corporate Research Agent

### プロダクトコンセプト
- **情報収集**: EDINET/TDnet/企業サイトを横断した開示書類の一元的な収集
- **自動解析**: PDF/XBRLの自動解析による財務データの構造化
- **分析支援**: 財務指標の自動計算と時系列分析の効率化
- **エージェント**: LLMを活用した企業分析支援

### プロダクトビジョン
個人投資家が企業の開示書類を効率的に収集・分析できる環境を提供する。EDINET、TDnet、企業サイトに分散している情報を統合的に取得し、PDF/XBRL形式の書類を自動解析して財務データを抽出する。これにより、機関投資家と同等の情報アクセス環境を個人投資家に提供し、投資判断の質を向上させる。

### 目的
- 複数サイト（EDINET/TDnet/企業サイト）に分散した開示書類の横断検索を実現
- PDF/XBRLファイルの自動解析による財務データの構造化
- 主要財務指標（ROE、ROA、自己資本比率等）の自動計算
- 将来的なLLM分析・ベクトル検索のためのデータ基盤構築

---

## ターゲットユーザー

### プライマリーペルソナ: 山田一郎（32歳、個人投資家）

**基本属性**:
- 投資歴7年、株式投資資産は約3,000万円
- 本業はIT企業のシステムエンジニア
- Python/Jupyter Notebookを使った分析に慣れている

**技術スタック**:
- Python、Jupyter Notebook、pandas、matplotlib
- Git、VS Code
- 基本的なSQL操作が可能

**現在の課題**:
- EDINETとTDnetを別々に検索する手間がかかる
- 有価証券報告書のPDFを手動で読み込み、財務データをExcelに転記している
- XBRLデータの活用方法がわからず、構造化データを取得できていない
- 競合比較や時系列分析のためのデータ収集に数時間かかる
- Bloomberg等の専門ツールは年間数百万円と高額で手が出ない

**期待する解決策**:
- 企業名を入力するだけで、関連する開示書類を一括取得したい
- 財務三表のデータを自動で抽出し、pandasのDataFrameとして取得したい
- 財務指標（ROE、営業利益率等）を自動計算してほしい
- Jupyter Notebookから直感的に操作できるAPIが欲しい

**1日の典型的なワークフロー**:
1. 朝: 保有銘柄の開示情報をチェック（30分）
2. 昼休み: 気になる銘柄の決算内容を確認
3. 夜: 新規投資候補の財務分析（1-2時間）
4. 週末: ポートフォリオ全体の分析レポート作成

---

## 成功指標(KPI)

### プライマリーKPI

- **企業分析時間の短縮**: 1社あたりの財務データ収集・整理時間を従来の2時間から15分以内に短縮（90%削減）
- **データ取得成功率**: EDINET対象書類の取得・解析成功率95%以上
- **財務指標計算精度**: 決算短信と照合して誤差1%以内

### セカンダリーKPI

- **対応企業数**: 日本の上場企業（約4,000社）の有価証券報告書に対応
- **API応答時間**: 書類一覧検索が3秒以内、財務データ取得が10秒以内
- **日次バッチ処理**: 1日あたりの新規開示（平均100-200件）を4時間以内に処理

---

## 機能要件

### コア機能(MVP) - P0

#### 1. EDINET API連携

**ユーザーストーリー**:
個人投資家として、企業コードまたは企業名で開示書類を検索するために、EDINET APIと連携した検索機能が欲しい

**受け入れ条件**:
- [ ] 企業コード（証券コード/EDINETコード）で書類を検索できる
- [ ] 企業名（部分一致）で書類を検索できる
- [ ] 期間を指定して検索結果を絞り込める
- [ ] 書類種別（有価証券報告書、四半期報告書、臨時報告書）でフィルタリングできる
- [ ] PDF/XBRLファイルをダウンロードできる
- [ ] APIレート制限に対応したリトライ機構を持つ

**検証方法**:
| 検証項目 | テストデータ | 合格基準 |
|---------|------------|---------|
| 企業コード検索 | 7203(トヨタ)、9984(ソフトバンクG)、6758(ソニー) | 3社全て書類一覧を取得できる |
| 企業名検索 | 「トヨタ」「ソフトバンク」で部分一致検索 | 関連企業が複数ヒットする |
| 期間指定 | 2023-01-01〜2024-12-31 | 指定期間内の書類のみ返却 |
| 書類種別フィルタ | 有価証券報告書のみ指定 | ordinance_code=010で正しくフィルタ |
| ファイルダウンロード | 上記3社の最新有報 | PDF/XBRL両方ダウンロード成功 |
| リトライ機構 | 意図的にレート制限を発生させる | 指数バックオフで最大3回リトライ |

**優先度**: P0(必須)

#### 2. PDF解析・マークダウン化

**ユーザーストーリー**:
個人投資家として、有価証券報告書のPDFから表や文章を抽出するために、PDF解析機能が欲しい

**受け入れ条件**:
- [ ] PDFからテキストを抽出できる
- [ ] 表データをマークダウン形式で出力できる
- [ ] 日本語の認識精度が95%以上（YOMITOKU + Gemini 2.5 Flash活用）
- [ ] 1書類（50-100ページ）の解析が5分以内に完了する

**検証方法**:
| 検証項目 | テストデータ | 合格基準 |
|---------|------------|---------|
| テキスト抽出 | 10社×3期（計30書類）の有報PDF | 本文テキストが抽出できる |
| 表データ抽出 | 財務諸表ページ（BS/PL/CF） | マークダウン表として構造化される |
| 日本語認識精度 | 30書類×10項目（計300項目） | 285項目以上（95%）が決算短信と一致（誤差1%以内） |
| 処理時間 | 50-100ページの標準的な有報 | pdfplumber優先で5分以内、Geminiフォールバック時15分以内 |

**テストデータセット（10社×3期）**:
- 製造業: トヨタ(7203)、ソニー(6758)、日立(6501)
- 情報通信: ソフトバンクG(9984)、NTT(9432)
- 金融: 三菱UFJ(8306)、東京海上(8766)
- 小売: セブン&アイ(3382)、ファーストリテイリング(9983)
- サービス: リクルート(6098)
- 対象期間: 2022年度、2023年度、2024年度

**優先度**: P0(必須)

#### 3. XBRL解析・財務データ抽出

**ユーザーストーリー**:
個人投資家として、有価証券報告書のXBRLから財務三表のデータを自動抽出するために、XBRL解析機能が欲しい

**受け入れ条件**:
- [ ] 貸借対照表（BS）の主要項目を抽出できる（総資産、流動資産、固定資産、負債、純資産等）
- [ ] 損益計算書（PL）の主要項目を抽出できる（売上高、営業利益、経常利益、当期純利益等）
- [ ] キャッシュフロー計算書（CF）の主要項目を抽出できる（営業CF、投資CF、財務CF）
- [ ] 連結/単体の区別ができる
- [ ] 当期/前期のデータを取得できる
- [ ] 日本基準・IFRS両方に対応できる（要素名の複数候補対応）
- [ ] edinet-xbrlライブラリで基本的な解析を行い、対応できない場合はBeautifulSoup + lxmlでフォールバック

**検証方法**:
| 検証項目 | テストデータ | 合格基準 |
|---------|------------|---------|
| BS抽出 | 10社×3期のXBRL | 総資産、純資産、負債が決算短信と一致（誤差1%以内） |
| PL抽出 | 10社×3期のXBRL | 売上高、営業利益、当期純利益が決算短信と一致（誤差1%以内） |
| CF抽出 | 10社×3期のXBRL | 営業CF、投資CF、財務CFが決算短信と一致（誤差1%以内） |
| 連結/単体 | 連結・単体両方提出企業 | 正しく区別して抽出できる |
| 当期/前期 | 比較情報含む書類 | コンテキスト期間で正しく判別 |
| 会計基準対応 | 日本基準5社、IFRS5社 | 両基準で主要項目抽出成功 |
| 処理時間 | 30書類 | 全書類5秒以内で解析完了 |

**テストデータセット（会計基準別）**:
- 日本基準: トヨタ(7203)、日立(6501)、NTT(9432)、三菱UFJ(8306)、セブン&アイ(3382)
- IFRS: ソニー(6758)、ソフトバンクG(9984)、東京海上(8766)、ファーストリテイリング(9983)、リクルート(6098)

**優先度**: P0(必須)

#### 4. 財務指標の計算

**ユーザーストーリー**:
個人投資家として、抽出した財務データから主要な財務指標を自動計算するために、指標計算機能が欲しい

**受け入れ条件**:
- [ ] 収益性指標を計算できる: ROE、ROA、営業利益率、経常利益率、売上高純利益率
- [ ] 安全性指標を計算できる: 自己資本比率、流動比率、固定比率、負債比率
- [ ] 効率性指標を計算できる: 総資産回転率、棚卸資産回転率、売上債権回転率
- [ ] 計算に必要なデータが不足している場合、適切なエラーメッセージを返す
- [ ] 計算結果をpandas DataFrameとして取得できる

**検証方法**:
| 検証項目 | テストデータ | 合格基準 |
|---------|------------|---------|
| ROE計算 | 10社の財務データ | 決算短信記載値と誤差0.1%以内 |
| ROA計算 | 10社の財務データ | 決算短信記載値と誤差0.1%以内 |
| 自己資本比率 | 10社の財務データ | 決算短信記載値と誤差0.1%以内 |
| 営業利益率 | 10社の財務データ | 手計算結果と完全一致 |
| データ不足時 | 必須項目欠損データ | 明確なエラーメッセージ（日本語）を返す |
| DataFrame出力 | 全指標計算結果 | pandas DataFrame形式で取得可能 |
| 処理時間 | 1企業の全指標計算 | 100ms以内 |

**検証用計算式**:
- ROE = 当期純利益 / 自己資本（期首期末平均）× 100
- ROA = 当期純利益 / 総資産（期首期末平均）× 100
- 自己資本比率 = 自己資本 / 総資産 × 100

**優先度**: P0(必須)

#### 5. データベース化

**ユーザーストーリー**:
個人投資家として、取得した財務データを永続化し、時系列分析や複数企業比較を行うために、データベース保存機能が欲しい

**受け入れ条件**:
- [ ] PostgreSQLにデータを保存できる
- [ ] pgvector拡張による将来のベクトル検索に対応した設計
- [ ] 書類メタデータ（提出日、書類種別、企業情報）を管理できる
- [ ] 財務データの重複登録を防止できる（冪等性）
- [ ] バッチ処理の中断・再開に対応できる

**検証方法**:
| 検証項目 | テストデータ | 合格基準 |
|---------|------------|---------|
| データ保存 | 10社×3期の財務データ | PostgreSQLへINSERT成功 |
| pgvector対応 | embedding列を含むテーブル | pgvector拡張でベクトル検索可能な設計 |
| メタデータ管理 | 書類メタデータ | 提出日、書類種別、企業情報が正しく保存・検索可能 |
| 冪等性 | 同一書類の再処理 | UPSERT処理で重複なし、データ上書き成功 |
| 中断・再開 | バッチ処理を途中で停止 | チェックポイントから再開可能 |
| データ整合性 | 外部キー制約 | 参照整合性が保たれる |

**冪等性の実現方法**:
- `doc_id`にUNIQUE制約を設定
- `INSERT ON CONFLICT UPDATE`（UPSERT）を使用
- 財務諸表: `(document_id, statement_type, fiscal_year, fiscal_period, consolidation_type)`の複合ユニーク制約

**優先度**: P0(必須)

### Python APIインターフェース

```python
# 基本的な使い方の例

from company_research_agent.clients.edinet_client import EDINETClient
from company_research_agent.core.config import EDINETConfig

# クライアント初期化（環境変数EDINET_API_KEYから自動読み込み）
config = EDINETConfig()
client = EDINETClient(config)

# 書類検索
documents = client.search(
    company_code="7203",  # トヨタ自動車
    doc_type="annual_report",  # 有価証券報告書
    start_date="2023-01-01",
    end_date="2024-12-31"
)

# 書類ダウンロード
xbrl_data = client.download(documents[0].doc_id, format="xbrl")

# XBRL解析
parser = XBRLParser()
financial_data = parser.parse(xbrl_data)

# 財務データ取得（pandas DataFrame）
bs = financial_data.balance_sheet  # 貸借対照表
pl = financial_data.income_statement  # 損益計算書
cf = financial_data.cash_flow  # キャッシュフロー計算書

# 財務指標計算
analyzer = FinancialAnalyzer(financial_data)
indicators = analyzer.calculate_all()
print(indicators)
# {
#   "ROE": 12.5,
#   "ROA": 5.2,
#   "operating_margin": 8.3,
#   "equity_ratio": 45.2,
#   ...
# }

# データベース保存
from company_research_agent import Database
db = Database(connection_string="postgresql://...")
db.save(financial_data)
```

### 重要機能(P1)

#### 6. 企業Webページからの情報取得

**ユーザーストーリー**:
個人投資家として、企業の公式サイトから決算説明会資料や中期経営計画を取得するために、Webスクレイピング機能が欲しい

**受け入れ条件**:
- [ ] 企業のIRページから決算短信・決算説明会資料（PDF）を取得できる
- [ ] 中期経営計画のPDFを取得できる
- [ ] IRニュースの一覧を取得できる
- [ ] robots.txtを遵守し、適切な間隔でアクセスする

**優先度**: P1(重要)

#### 7. LLM分析機能（LangGraph構造化）

**ユーザーストーリー**:
個人投資家として、取得した財務データと開示書類の内容をAIで分析し、要約や洞察を得るために、LLM分析機能が欲しい

**受け入れ条件**:
- [ ] 有価証券報告書の「事業の状況」「経営者による分析」等を要約できる（BusinessSummaryNode）
- [ ] 財務データの特徴や変化点を自動で抽出・解説できる（FinancialAnalysisNode）
- [ ] リスク要因の抽出と整理ができる（RiskExtractionNode）
- [ ] 前期比較による変化点の自動検出ができる（PeriodComparisonNode）
- [ ] 各分析結果を統合したレポートを生成できる（AggregatorNode）
- [ ] 各ノードを個別に実行できる（部分実行対応）
- [ ] 分析ノード（Business, Risk, Financial）を並列実行できる
- [x] 複数のLLMプロバイダー（OpenAI、Google、Anthropic、Ollama）を切り替えて使用できる
- [x] 環境変数（LLM_PROVIDER）でプロバイダーを設定できる
- [x] ビジョン機能（PDF解析用）で別のプロバイダーを指定できる（LLM_VISION_PROVIDER）

**LangGraphワークフロー構成**:
```
EDINETNode → PDFParseNode → [BusinessSummaryNode, RiskExtractionNode, FinancialAnalysisNode]（並列） → PeriodComparisonNode → AggregatorNode
```

**検証方法**:
| 検証項目 | テストデータ | 合格基準 |
|---------|------------|---------|
| 事業要約 | 10社の有報 | 主要事業・戦略が正確に要約される |
| 財務分析 | 10社の有報 | 主要財務指標の変化が検出される |
| リスク抽出 | 10社の有報 | リスク項目が5件以上抽出される |
| 前期比較 | 5社×2期 | 重要な変化点が3件以上検出される |
| 並列実行 | 3ノード同時 | 逐次実行より高速化 |
| 個別出力 | 各ノード単独 | 他ノードに影響なく実行可能 |

**優先度**: P0(必須)

#### 8. ベクトル検索

**ユーザーストーリー**:
個人投資家として、類似した財務特性を持つ企業や、特定のキーワードに関連する開示内容を検索するために、ベクトル検索機能が欲しい

**受け入れ条件**:
- [ ] pgvectorを活用した類似企業検索ができる
- [ ] 財務指標の類似性に基づく企業検索ができる
- [ ] 開示書類の内容に対するセマンティック検索ができる
- [ ] 検索結果の類似度スコアを表示できる

**優先度**: P1(重要)

### 将来的な機能(Post-MVP) - P2

#### 9. TDnet連携

TDnetのAPIは有料（月額数十万円）のため、優先度を下げて将来の課題とする。

**優先度**: P2(できれば)

---

## 非機能要件

### パフォーマンス

#### 書類一覧の検索
- **目標**: 3秒以内
- **測定条件**: EDINET API正常稼働時、ネットワーク遅延100ms以下
- **依存要因**: EDINET APIの応答時間（通常1-2秒）

#### PDF解析
- **目標**: 1書類（50-100ページ）あたり5分以内
- **測定条件**:
  - ネットワーク帯域: 10Mbps以上
  - 処理方式: pdfplumber/pymupdf4llm優先、Gemini APIはフォールバック
  - Gemini API使用時: RPM制限60回/分を考慮
- **最悪ケース**: 全ページGemini API使用時は15分程度
- **注記**: 複雑な表が多い書類はGemini APIフォールバック率が上昇し処理時間増加

#### XBRL解析
- **目標**: 1書類あたり5秒以内
- **測定条件**:
  - ローカル処理（外部API依存なし）
  - edinet-xbrlライブラリ優先、BeautifulSoup/lxmlフォールバック
- **最悪ケース**: 複雑なタクソノミの場合10秒程度

#### 財務指標計算
- **目標**: 1企業あたり100ms以内
- **測定条件**: メモリ上のデータに対する計算処理

#### 日次バッチ処理
- **目標**: 新規開示（100-200件/日）を4時間以内に処理
- **測定条件**:
  - 並列処理: 5並列
  - EDINET APIレート制限: 60回/分遵守
  - PDF解析: 平均3分/書類として計算
- **最悪ケース**: 開示集中日（決算発表日）は6時間程度

### ユーザビリティ
- Jupyter Notebookから直感的に利用できるPython API
- 明確なエラーメッセージと例外処理（日本語対応）
- 処理状況のログ出力（プログレスバー、所要時間表示）
- サンプルノートブックの提供（基本操作、財務分析例）
- API仕様のドキュメント（docstring、型ヒント完備）

### 信頼性
- API呼び出しのリトライ機構（指数バックオフ、最大3回）
- 処理失敗時の再実行可能性（冪等性の担保）
- データ整合性チェック（重複排除、検証ログ）
- バッチ処理の中断・再開対応（チェックポイント機能）
- データ損失ゼロ（トランザクション管理）

### セキュリティ
- EDINET APIキーの安全な管理（環境変数、設定ファイル）
- データベース接続情報の暗号化
- 機密情報のログ出力禁止

### スケーラビリティ
- 対象企業数: 数百社（特定セクターや指数構成銘柄）を想定
- 過去10年分のデータ保持（EDINET保持期間に対応）
- 新しいデータソースの追加が容易な設計（プラグイン方式）
- 新しい財務指標の追加が容易（設定ファイルベース）

---

## 技術スタック

| 項目 | 技術 | 選定理由 |
|------|------|----------|
| 言語 | Python 3.11+ | データ分析エコシステム、型ヒント完備 |
| Webフレームワーク | FastAPI | 高速、型安全、OpenAPI自動生成 |
| PDF解析 | YOMITOKU + Gemini 2.5 Flash | 日本語表認識に強い |
| XBRL解析 | edinet-xbrl + BeautifulSoup/lxml | edinet-xbrlで基本対応、複雑なケースは自前実装でフォールバック |
| データベース | PostgreSQL + pgvector | ベクトル検索対応（将来のLLM分析用） |
| 簡易UI | Streamlit | 高速プロトタイピング |
| テスト | pytest | 標準的なテストフレームワーク |
| ドキュメント | Sphinx + MyST | Markdown対応のドキュメント生成 |

---

## スコープ外

明示的にスコープ外とする項目:

- **株価関連指標（PER、PBR、配当利回り等）**: 別プロジェクトで対応予定
- **リアルタイム株価データの取得**: 本プロジェクトは開示書類に特化
- **TDnet API連携（有料）**: 将来の課題として記録、当面はEDINETのみ
- **海外企業の財務データ**: 日本の上場企業のみを対象
- **モバイルアプリ**: デスクトップ環境（Jupyter Notebook）が主な利用形態
- **マルチユーザー機能**: 個人利用を想定

---

## リスクと対策

| リスク | 影響度 | 発生可能性 | 対策 |
|--------|--------|------------|------|
| XBRL解析の複雑さ（EDINET独自タクソノミ） | 高 | 高 | 主要企業でテスト、複数要素名候補のフォールバック |
| EDINET APIのレート制限 | 中 | 中 | 適切な間隔でリクエスト、リトライ機構 |
| PDF解析の精度（複雑な表） | 中 | 中 | YOMITOKU + Gemini活用、手動補正の仕組み |
| 会計基準の違い（日本基準/IFRS） | 中 | 高 | 両方の要素名に対応、変換ロジック実装 |

---

## 開発フェーズ

### フェーズ1: EDINET API連携（PoC）【完了】

**目標**: EDINET APIの基本機能を実装し、動作確認を完了する

**実装内容**:
- APIキー取得・認証実装
- 書類一覧取得（メタデータ→詳細の2段階取得）
- 書類ダウンロード（ZIP/PDF/XBRL）
- エラーハンドリング

**成功基準**:
- [x] 書類一覧取得APIが正常に動作する（テスト企業3社で確認）
- [x] 書類ダウンロードが成功する（XBRL/PDF両方）
- [x] APIレート制限エラーに対するリトライ処理が動作する
- [x] ユニットテストカバレッジ80%以上

### フェーズ2: PDF解析・マークダウン化【完了】

**目標**: PDFから表や文章を抽出し、マークダウン形式で出力できる状態にする

**実装内容**:
- pdfplumber/pymupdf4llmによる基本解析
- YOMITOKU（日本語OCR）による高精度解析
- Gemini APIによるフォールバック解析
- 段階的解析戦略の実装

**成功基準**:
- [x] テキストPDFからテキストを抽出できる
- [x] 表データをマークダウン形式で出力できる
- [x] 日本語の認識精度が95%以上
- [x] 1書類（50-100ページ）の解析が5分以内に完了する

### フェーズ3: LLM分析機能（LangGraph構造化）【完了】

**目標**: LangGraphベースのワークフローで、有価証券報告書のLLM分析機能を実装する

**実装内容**:
- フェーズ3.1: 基盤整備（State設計、ノード基底クラス）
- フェーズ3.2: 各ノード実装（並列で試行錯誤可能）
  - EDINETNode: EDINET書類取得
  - PDFParseNode: PDF解析・マークダウン化
  - BusinessSummaryNode: 事業要約
  - RiskExtractionNode: リスク抽出
  - FinancialAnalysisNode: 財務分析
  - PeriodComparisonNode: 前期比較
  - AggregatorNode: 結果統合
- フェーズ3.3: ワークフロー統合

**成功基準**:
- [x] 各ノードが個別に実行できる
- [x] 分析ノード（Business, Risk, Financial）が並列実行できる
- [x] 前期比較機能が動作する
- [x] 統合レポートが生成される
- [x] ユニットテストがパスする（29件パス）

### フェーズ4: XBRL解析（PoC）

**目標**: XBRLから財務三表の主要項目を抽出できる状態にする

**実装内容**:
- edinet-xbrlライブラリでの基本実装
- BeautifulSoup + lxmlによるフォールバック実装
- 主要財務項目の抽出（売上高、営業利益、総資産等）
- 複数要素名候補によるフォールバック対応
- コンテキスト解析（期間、連結/単体の判別）

**成功基準**:
- [ ] 日本基準企業3社でBS/PL/CFの主要項目を抽出できる
- [ ] IFRS企業2社でBS/PL/CFの主要項目を抽出できる
- [ ] 連結/単体の区別が正しくできる
- [ ] 抽出値が決算短信と一致する（誤差1%以内）
- [ ] ユニットテストカバレッジ80%以上

### フェーズ5: 統合・検証

**目標**: 10社のテストデータで検証を完了し、実用可能な状態にする

**実装内容**:
- 10社程度でのテスト
- データクレンジング（スケール変換、負数処理）
- Jupyter Notebook用APIの整備
- PostgreSQLへのデータ保存

**成功基準**:
- [ ] テストデータセット10社×3期（計30書類）で検証完了
- [ ] データ取得・解析成功率95%以上（30書類中28書類以上）
- [ ] PostgreSQLへのデータ保存・検索が正常動作
- [ ] Jupyter Notebookサンプルが動作する
- [ ] 統合テストが全てパス

### フェーズ6: 機能拡充

**目標**: 財務指標計算、バッチ処理を実装し、MVPを完成させる

**実装内容**:
- 財務指標計算の実装
- 日次バッチ処理の実装
- ドキュメント整備

**成功基準**:
- [ ] 財務指標（ROE、ROA、自己資本比率等）が正しく計算される
- [ ] 日次バッチ処理が100件/4時間以内で完了
- [ ] APIドキュメント（Sphinx）が生成される
- [ ] 全てのP0機能の受け入れ条件をクリア

### 将来のP1機能

**ベクトル検索**:
- pgvectorを活用した類似企業検索
- 財務指標の類似性に基づく企業検索
- 開示書類の内容に対するセマンティック検索

**企業Webページからの情報取得**:
- 企業のIRページから決算短信・決算説明会資料（PDF）を取得
- 中期経営計画のPDFを取得
- IRニュースの一覧を取得

---

**作成日**: 2026年1月16日
**バージョン**: 1.0
**ステータス**: ドラフト
